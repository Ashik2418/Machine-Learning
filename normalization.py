# -*- coding: utf-8 -*-
"""normalization.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1lNiy7vQ6k8mgpGz5e-9Qr0Z4Bd5L6bPd
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

df = pd.read_csv('/content/Wine dataset.csv',header = None, usecols = [0,1,2])
df.columns = ['class','Alcohol','Malic acid']
df = df.drop(index=0)

df

df['Malic acid'] = pd.to_numeric(df['Malic acid'], errors='coerce')
sns.kdeplot(df['Malic acid'])

df['Alcohol'] = pd.to_numeric(df['Alcohol'], errors='coerce')
sns.kdeplot(df['Alcohol'])

color_dict = {1:'red',3:'green',2:'blue'}
# Pass 'x' and 'y' as keyword arguments
sns.scatterplot(x=df['Alcohol'], y=df['Malic acid'], hue=df['class'], palette=color_dict)

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(df.drop('class',axis=1), df['class'], test_size=0.3, random_state=0)

X_train.shape,X_test.shape

"""# **Normalization**"""

from sklearn.preprocessing import MinMaxScaler
scaler = MinMaxScaler()
scaler.fit(X_train)
X_train_scaled = scaler.transform(X_train)
X_test_scaled = scaler.transform(X_test)

X_train_scaled = pd.DataFrame(X_train_scaled,columns=X_train.columns)
X_test_scaled = pd.DataFrame(X_test_scaled,columns=X_test.columns)

np.round(X_train.describe(),1)

np.round(X_train_scaled.describe(),1)

"""# **Comparison of Distribution using Normalization**"""

fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(12, 4))
#Before Scaling
ax1.set_title('Before Scaling')
sns.kdeplot(X_train['Alcohol'], ax=ax1)
#after Scaling
ax2.set_title('After Scaling')
sns.kdeplot(X_train_scaled['Alcohol'], ax=ax2)
plt.show()

"""# **Using Logistic Algorithm**

This is best for this dataset because normalization scaling Accuracy 40%
"""

from sklearn.linear_model import LogisticRegression
log_reg = LogisticRegression()
log_reg_scaled = LogisticRegression()
log_reg.fit(X_train,y_train)
log_reg_scaled.fit(X_train_scaled,y_train)
LogisticRegression()
y_pred = log_reg.predict(X_test)
y_pred_scaled = log_reg_scaled.predict(X_test_scaled)

from sklearn.metrics import accuracy_score
print(accuracy_score(y_test,y_pred))
print(accuracy_score(y_test,y_pred_scaled))

"""This is not Best for this Dataset because accurracy after Scaling 29%

"""

from sklearn.tree import DecisionTreeClassifier
log_reg = DecisionTreeClassifier()
log_reg_scaled = DecisionTreeClassifier()
log_reg.fit(X_train,y_train)
log_reg_scaled.fit(X_train_scaled,y_train)
DecisionTreeClassifier()
y_pred = log_reg.predict(X_test)
y_pred_scaled = log_reg_scaled.predict(X_test_scaled)

from sklearn.metrics import accuracy_score
print(accuracy_score(y_test,y_pred))
print(accuracy_score(y_test,y_pred_scaled))